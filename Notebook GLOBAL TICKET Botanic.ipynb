{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'pandas'])\n",
    "pip.main(['install', 'matplotlib'])\n",
    "pip.main(['install', 'seaborn'])\n",
    "pip.main(['install', 'scikit-learn'])\n",
    "!pip.main(['install', 'nbmerge'])\n",
    "pip.main(['install', 'nbformat'])\n",
    "!pip install nbformat ipynb-py-convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nbformat\n",
    "import nbmerge\n",
    "import json\n",
    "from nbformat import read, write\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebooks merged into merged_Notebook GLOBAL TICKET Botanic.ipynb\n"
     ]
    }
   ],
   "source": [
    "def merge_notebooks(filenames):\n",
    "    merged_notebook = nbformat.v4.new_notebook()\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            notebook = nbformat.read(f, as_version=4)\n",
    "            merged_notebook.cells.extend(notebook.cells)\n",
    "    return merged_notebook\n",
    "\n",
    "notebooks_to_merge = [\n",
    "    \"Notebook LIGNES_TICKET Botanic.ipynb\",\n",
    "    \"Notebook ENTETE TICKET Botanic.ipynb\"\n",
    "]\n",
    "\n",
    "merged_notebook = merge_notebooks(notebooks_to_merge)\n",
    "\n",
    "output_filename = \"merged_Notebook GLOBAL TICKET Botanic.ipynb\"\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(merged_notebook, f)\n",
    "\n",
    "print(f\"Notebooks merged into {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merged_Notebook_GLOBAL_TICKET_Botanic.ipynb\", 'r', encoding='utf-8') as f:\n",
    "    merged_notebook = nbformat.read(f, as_version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code cell:\n",
      "import pip\n",
      "pip.main(['install', 'pandas'])\n",
      "pip.main(['install', 'matplotlib'])\n",
      "pip.main(['install', 'seaborn'])\n",
      "pip.main(['install', 'scikit-learn'])\n",
      "\n",
      "Markdown cell:\n",
      "# CHARGEMENT DES BIBLIOTHEQUES\n",
      "\n",
      "Code cell:\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.datasets import make_classification\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "Markdown cell:\n",
      "Chargement du jeu de données \"LIGNES_TICKET_V4\"\n",
      "\n",
      "Code cell:\n",
      "dataset_path = \"C:\\\\Users\\\\belga\\\\OneDrive\\\\Bureau\\\\EMBA Big Data\\\\Module Datascience\\\\Projet Data Science S2 2024\\\\LIGNES_TICKET_V4.csv\"\n",
      "data3 = pd.read_csv(dataset_path, sep='|', low_memory=False)\n",
      "print(data3.shape)\n",
      "print(list(data3.columns))\n",
      "\n",
      "Markdown cell:\n",
      "La ligne de code ci-dessous nous permet de voir le détail des colonnes de notre jeu de données ainsi que le type de données (chaîne de caractères, numérique)\n",
      "\n",
      "Code cell:\n",
      "data3.info()\n",
      "\n",
      "Markdown cell:\n",
      "Aperçu du jeu de données.\n",
      "\n",
      "Code cell:\n",
      "data3\n",
      "\n",
      "Markdown cell:\n",
      "Afin d'exploiter de façon optimale les informations, nous allons convetir les l'ID TICKET et le NUM LIGNE TICKET en caractère. A l'inverse, nous devons convertir les quantités, les montants, les totaux et les marges en valeur numérique.\n",
      "\n",
      "Code cell:\n",
      "data3['IDTICKET'] = data3['IDTICKET'].astype(str)\n",
      "data3['NUMLIGNETICKET'] = data3['NUMLIGNETICKET'].astype(str)\n",
      "\n",
      "Code cell:\n",
      "data3[\"QUANTITE\"]=data3['QUANTITE'].str.replace(',', '.').astype(float)\n",
      "\n",
      "Code cell:\n",
      "data3[\"TOTAL\"]=data3['TOTAL'].str.replace(',', '.').astype(float)\n",
      "\n",
      "Code cell:\n",
      "data3[\"MONTANTREMISE\"]=data3['MONTANTREMISE'].str.replace(',', '.').astype(float)\n",
      "\n",
      "Code cell:\n",
      "data3[\"MARGESORTIE\"]=data3['MARGESORTIE'].str.replace(',', '.').astype(float)\n",
      "\n",
      "Markdown cell:\n",
      "Vérification du traitement.\n",
      "\n",
      "Code cell:\n",
      "data3\n",
      "\n",
      "Markdown cell:\n",
      "#data3['TOTAL'].replace({'': '0.0'}, inplace=True)\n",
      "\n",
      "Markdown cell:\n",
      "Vérification du traitement.\n",
      "\n",
      "Code cell:\n",
      "data3.info()\n",
      "\n",
      "Markdown cell:\n",
      "La ligne de code ci-dessous nous permet d'identifier les valeurs en doublons qui conviendra de traiter.\n",
      "\n",
      "Code cell:\n",
      "print(data3.duplicated().sum())\n",
      "data = data3.drop_duplicates()\n",
      "\n",
      "Markdown cell:\n",
      "Nous allons désormais procéder au traitement de ces doublons.\n",
      "\n",
      "Code cell:\n",
      "data3.drop_duplicates(keep='first', inplace=True)\n",
      "\n",
      "Markdown cell:\n",
      "Code de vérification.\n",
      "\n",
      "Code cell:\n",
      "print(data3.duplicated().sum())\n",
      "\n",
      "Markdown cell:\n",
      "Nous procédons également à la vérification de présence ou non de valeurs manquantes (aucune valeur détectée).\n",
      "\n",
      "Code cell:\n",
      "pd.DataFrame(index=data.columns, columns=['%_missing_values'], data= (data.isna().sum().values / len(data)*100))\n",
      "\n",
      "Markdown cell:\n",
      "Il convient à présent de vérifier la présence de valeur aberrantes.\n",
      "\n",
      "Code cell:\n",
      "# Visualisation des boxplots des variables numériques\n",
      "sns.boxplot(data3)\n",
      "\n",
      "Markdown cell:\n",
      "La série de code ci-dessous permet de traiter les valeurs aberrantes en présence, sur chacune des catégories concernées.\n",
      "\n",
      "Code cell:\n",
      "''' Detection '''\n",
      "# IQR\n",
      "Q1 = np.percentile(data3['QUANTITE'], 25,\n",
      "                   interpolation = 'midpoint')\n",
      " \n",
      "Q3 = np.percentile(data3['QUANTITE'], 75,\n",
      "                   interpolation = 'midpoint')\n",
      "IQR = Q3 - Q1\n",
      " \n",
      "print(\"Old Shape: \", data3.shape)\n",
      "\n",
      "Code cell:\n",
      "# Upper bound\n",
      "upper = np.where(data3['QUANTITE'] >= (Q3+1.5*IQR))\n",
      "# Lower bound\n",
      "lower = np.where(data3['QUANTITE'] <= (Q1-1.5*IQR))\n",
      "\n",
      "Code cell:\n",
      "# IQR\n",
      "Q1 = np.percentile(data3['TOTAL'], 25,\n",
      "                   interpolation = 'midpoint')\n",
      " \n",
      "Q3 = np.percentile(data3['TOTAL'], 75,\n",
      "                   interpolation = 'midpoint')\n",
      "IQR = Q3 - Q1\n",
      " \n",
      "print(\"Old Shape: \", data3.shape)\n",
      "\n",
      "Code cell:\n",
      "# Upper bound\n",
      "upper = np.where(data3['TOTAL'] >= (Q3+1.5*IQR))\n",
      "# Lower bound\n",
      "lower = np.where(data3['TOTAL'] <= (Q1-1.5*IQR))\n",
      "\n",
      "Code cell:\n",
      "# IQR\n",
      "Q1 = np.percentile(data3['MONTANTREMISE'], 25,\n",
      "                   interpolation = 'midpoint')\n",
      " \n",
      "Q3 = np.percentile(data3['MONTANTREMISE'], 75,\n",
      "                   interpolation = 'midpoint')\n",
      "IQR = Q3 - Q1\n",
      " \n",
      "print(\"Old Shape: \", data3.shape)\n",
      "\n",
      "Code cell:\n",
      "# Upper bound\n",
      "upper = np.where(data3['MONTANTREMISE'] >= (Q3+1.5*IQR))\n",
      "# Lower bound\n",
      "lower = np.where(data3['MONTANTREMISE'] <= (Q1-1.5*IQR))\n",
      "\n",
      "Code cell:\n",
      "# IQR\n",
      "Q1 = np.percentile(data3['MARGESORTIE'], 25,\n",
      "                   interpolation = 'midpoint')\n",
      " \n",
      "Q3 = np.percentile(data3['MARGESORTIE'], 75,\n",
      "                   interpolation = 'midpoint')\n",
      "IQR = Q3 - Q1\n",
      " \n",
      "print(\"Old Shape: \", data3.shape)\n",
      "\n",
      "Code cell:\n",
      "# Upper bound\n",
      "upper = np.where(data3['MARGESORTIE'] >= (Q3+1.5*IQR))\n",
      "# Lower bound\n",
      "lower = np.where(data3['MARGESORTIE'] <= (Q1-1.5*IQR))\n",
      "\n",
      "Code cell:\n",
      "print(\"New Shape: \", data3.shape)\n",
      "\n",
      "Code cell:\n",
      "import pip\n",
      "pip.main(['install', 'pandas'])\n",
      "pip.main(['install', 'matplotlib'])\n",
      "pip.main(['install', 'seaborn'])\n",
      "pip.main(['install', 'scikit-learn'])\n",
      "\n",
      "Markdown cell:\n",
      "# CHARGEMENT DES BIBLIOTHEQUES\n",
      "\n",
      "Code cell:\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.datasets import make_classification\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "Markdown cell:\n",
      "Chargement du jeu de données ENTETES TICKET V4.\n",
      "\n",
      "Code cell:\n",
      "dataset_path = \"C:\\\\Users\\\\belga\\\\OneDrive\\\\Bureau\\\\EMBA Big Data\\\\Module Datascience\\\\Projet Data Science S2 2024\\\\ENTETES_TICKET_V4.csv\"\n",
      "data2 = pd.read_csv(dataset_path, sep='|', low_memory=False)\n",
      "print(data2.shape)\n",
      "print(list(data2.columns))\n",
      "\n",
      "\n",
      "Markdown cell:\n",
      "La ligne de code ci-dessous nous permet de connaître le détail des colonnes ainsi que le type de données constituant notre base (numérique ou caractères).\n",
      "\n",
      "Code cell:\n",
      "data2.info()\n",
      "\n",
      "Markdown cell:\n",
      "Aperçu de notre jeu de données. \n",
      "\n",
      "Code cell:\n",
      "data2\n",
      "\n",
      "Markdown cell:\n",
      "Afin d'exploiter de façon optimale les informations, nous allons convetir les l'ID TICKET et le NUM LIGNE TICKET en caractère. A l'inverse, nous devons convertir le total TTC en valeur numérique.\n",
      "\n",
      "Code cell:\n",
      "data2['IDTICKET'] = data2['IDTICKET'].astype(str)\n",
      "data2['IDCLIENT'] = data2['IDCLIENT'].astype(str)\n",
      "\n",
      "Code cell:\n",
      "data2['TIC_TOTALTTC'] = data2['TIC_TOTALTTC'].str.replace(',', '.')\n",
      "\n",
      "Code cell:\n",
      "data2['TIC_TOTALTTC'] = data2['TIC_TOTALTTC'].str.strip('\\\"')\n",
      "\n",
      "Code cell:\n",
      "data2['TIC_TOTALTTC'] = pd.to_numeric(data2['TIC_TOTALTTC'], errors='coerce')\n",
      "\n",
      "Markdown cell:\n",
      "Vérification du traitement.\n",
      "\n",
      "Code cell:\n",
      "data2.info()\n",
      "\n",
      "Code cell:\n",
      "data2\n",
      "\n",
      "Markdown cell:\n",
      "La ligne de code ci-dessous nous permet de formater le format de la date.\n",
      "\n",
      "Code cell:\n",
      "from datetime import datetime\n",
      "data2['TIC_DATE'] = pd.to_datetime(data2['TIC_DATE'], format=\"%Y-%m-%d %H:%M:%S\")\n",
      "data2['TIC_DATE'] = data2['TIC_DATE'].dt.strftime(\"%d/%m/%Y\")\n",
      "\n",
      "Markdown cell:\n",
      "Vérification du traitement.\n",
      "\n",
      "Code cell:\n",
      "data2\n",
      "\n",
      "Markdown cell:\n",
      "Cette ligne de code nous permet d'identifier le nombre d'occurence de chaque code magasin, pour identifier les éventuels regroupements à effectuer. \n",
      "\n",
      "Code cell:\n",
      "#modalités variables:\n",
      "data2['MAG_CODE'].value_counts(dropna = False)\n",
      "\n",
      "Markdown cell:\n",
      "La ligne de code ci-dessous nous permet d'identifier la présence ou non de valeur(s) en doublons.\n",
      "\n",
      "Code cell:\n",
      "print(data2.duplicated().sum())\n",
      "data = data2.drop_duplicates()\n",
      "\n",
      "Markdown cell:\n",
      "La ligne de code ci-dessous nous permet d'identifier la présence ou non de valeur(s) manquante(s)\n",
      "\n",
      "Code cell:\n",
      "pd.DataFrame(index=data.columns, columns=['%_missing_values'], data= (data.isna().sum().values / len(data)*100))\n",
      "\n",
      "Markdown cell:\n",
      "Il convient à présent de vérifier la présence de valeur aberrantes.\n",
      "\n",
      "Code cell:\n",
      "#1ère méthode boxplot\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Visualisation des boxplots des variables numériques\n",
      "sns.boxplot(data2)\n",
      "\n",
      "Markdown cell:\n",
      "La série de code ci-dessous permet de traiter les valeurs aberrantes en présence.\n",
      "\n",
      "Code cell:\n",
      "''' Detection '''\n",
      "# IQR\n",
      "Q1 = np.percentile(data2['TIC_TOTALTTC'], 25,\n",
      "                   interpolation = 'midpoint')\n",
      " \n",
      "Q3 = np.percentile(data2['TIC_TOTALTTC'], 75,\n",
      "                   interpolation = 'midpoint')\n",
      "IQR = Q3 - Q1\n",
      " \n",
      "print(\"Old Shape: \", data2.shape)\n",
      "\n",
      "Code cell:\n",
      "# Upper bound\n",
      "upper = np.where(data2['TIC_TOTALTTC'] >= (Q3+1.5*IQR))\n",
      "# Lower bound\n",
      "lower = np.where(data2['TIC_TOTALTTC'] <= (Q1-1.5*IQR))\n",
      "\n",
      "Code cell:\n",
      "''' Removing the Outliers '''\n",
      "data2.drop(upper[0], inplace = True)\n",
      "data2.drop(lower[0], inplace = True)\n",
      "\n",
      "Code cell:\n",
      "print(\"New Shape: \", data2.shape)\n",
      "\n",
      "Markdown cell:\n",
      "CALCUL DU NOMBRES DE MAGASINS (Mag Code) FREQUENTE PAR UN CLIENT (ID Client).\n",
      "\n",
      "Code cell:\n",
      "data2['IDCLIENT'] = data2['IDCLIENT'].astype(float)\n",
      "\n",
      "Code cell:\n",
      "data2['IDCLIENT'] = data2['IDCLIENT'].astype(int)\n",
      "\n",
      "Code cell:\n",
      "data2.info()\n",
      "\n",
      "Code cell:\n",
      "FREQUENCE_MAG = data2.groupby('IDCLIENT')['MAG_CODE'].nunique()\n",
      "\n",
      "Code cell:\n",
      "data2.insert(loc=5, column='FREQUENCE_MAG', value=FREQUENCE_MAG)\n",
      "\n",
      "Code cell:\n",
      "data2['FREQUENCE_MAG'].value_counts()\n",
      "\n",
      "Markdown cell:\n",
      "CALCUL D'ANCIENNETE ENTRE LES 2 DERNIERES COMMANDES (TIC DATE) D'UN CLIENT (ID Client).\n",
      "\n",
      "Code cell:\n",
      "data2['TIC_DATE'] = pd.to_datetime(data2['TIC_DATE'], format='%d/%m/%Y', errors='coerce')\n",
      "\n",
      "Code cell:\n",
      "data2.sort_values(by=['IDCLIENT', 'TIC_DATE'], inplace=True)\n",
      "\n",
      "Code cell:\n",
      "ANCIENNETE_CDE = data2.groupby('IDCLIENT')['TIC_DATE'].diff()\n",
      "\n",
      "Code cell:\n",
      "data2.insert(loc=6, column='ANCIENNETE_CDE', value=ANCIENNETE_CDE)\n",
      "\n",
      "Code cell:\n",
      "data2['ANCIENNETE_CDE'].value_counts()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher le contenu des cellules\n",
    "for cell in merged_notebook.cells:\n",
    "    if cell.cell_type == 'code':\n",
    "        print(f\"Code cell:\\n{cell.source}\\n\")\n",
    "    elif cell.cell_type == 'markdown':\n",
    "        print(f\"Markdown cell:\\n{cell.source}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
